{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pkolachi/lexicalnormalization/blob/master/exptnbs/LexicalNormalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzRtzY3ApXhe"
   },
   "source": [
    "### Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywhY3ZLXJs0P",
    "outputId": "5cf61797-4991-48da-d089-a352578abaf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'lexicalnormalization' already exists and is not an empty directory.\n",
      "Requirement already up-to-date: pandas in /home/pkolachi/.local/lib/python3.8/site-packages (1.2.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /home/pkolachi/.local/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.16.5 in /home/pkolachi/.local/lib/python3.8/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/pkolachi/.local/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already up-to-date: sklearn in /home/pkolachi/.local/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /home/pkolachi/.local/lib/python3.8/site-packages (from sklearn) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /home/pkolachi/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /home/pkolachi/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/pkolachi/.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pkolachi/lexicalnormalization\n",
    "%pip install --user -U pandas\n",
    "%pip install --user -U sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GTkdFPXmKBCH"
   },
   "outputs": [],
   "source": [
    "REPO_NAME = 'lexicalnormalization'\n",
    "LANGS = {'da': 'Danish',\n",
    "         'en': 'English',\n",
    "         'es': 'Spanish',\n",
    "         'fr': 'French',\n",
    "         'hr': 'Croatian',\n",
    "         'iden': 'Indonesian-English',\n",
    "         'it': 'Italian',\n",
    "         'nl': 'Dutch',\n",
    "         'sl': 'Slovenian',\n",
    "         'sr': 'Serbian',\n",
    "         'tr': 'Turkish',\n",
    "         'trde': 'Turkish-German',\n",
    "         }\n",
    "SMPLS = ['en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSzppLsjpdql"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VTSBr-AMNXzf"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "from operator import itemgetter\n",
    "import os.path \n",
    "import pandas as pd\n",
    "\n",
    "def read_data(inpfile):\n",
    "  with open(inpfile) as ins:\n",
    "    sent = []\n",
    "    for lne in ins:\n",
    "      if not lne.strip():\n",
    "        yield sent\n",
    "        sent = []\n",
    "      else:\n",
    "        sent.append(lne.strip('\\n').split('\\t', 1))\n",
    "\n",
    "DATA = defaultdict(lambda: defaultdict(lambda: ([], [])))\n",
    "for lang in SMPLS:\n",
    "  datadir = os.path.join(REPO_NAME, 'data', lang)\n",
    "  trnfile = os.path.join(datadir, 'train.norm')\n",
    "  devfile = os.path.join(datadir, 'dev.norm')\n",
    "  tstfile = os.path.join(datadir, 'test.norm')\n",
    "  if os.path.isdir(datadir) and os.path.isfile(trnfile):\n",
    "    crp = list(read_data(trnfile))\n",
    "    X = list(map(itemgetter(0), crp))  # load input (un-normalized sentences)\n",
    "    Y = list(map(itemgetter(1), crp))  # load output (normalized sentences)\n",
    "    DATA[lang]['fulltrn'] = (X, Y)\n",
    "  if os.path.isdir(datadir) and os.path.isfile(devfile):\n",
    "    crp = list(read_data(devfile))\n",
    "    DATA[lang]['dev'] = (list(map(itemgetter(0), crp)), \n",
    "                         list(map(itemgetter(1), crp)))\n",
    "  if os.path.isdir(datadir) and os.path.isfile(tstfile):\n",
    "    crp = list(read_data(tstfile))\n",
    "    DATA[lang]['tst'] = (list(map(itemgetter(0), crp)), \n",
    "                         list(map(itemgetter(1), crp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V4J-9JaRXMOX"
   },
   "outputs": [],
   "source": [
    "TST_RATIO = 0.15\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "for lang in SMPLS:\n",
    "  if 'fulltrn' in DATA[lang]:\n",
    "    trn_x, hld_x, trn_y, hld_y = train_test_split(DATA[lang]['fulltrn'][0], \n",
    "                                                  DATA[lang]['fulltrn'][1], \n",
    "                                                  test_size=TST_RATIO, \n",
    "                                                  random_state=0, \n",
    "                                                  shuffle=False)\n",
    "    DATA[lang]['trn'] = (trn_x, trn_y)\n",
    "    DATA[lang]['hld'] = (hld_x, hld_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>Training</th>\n",
       "      <th>Held-out</th>\n",
       "      <th>Development</th>\n",
       "      <th>Testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>2006</td>\n",
       "      <td>354</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang  Training  Held-out  Development  Testing\n",
       "0  English      2006       354          590        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['lang'] + ['Training', 'Held-out', 'Development', 'Testing']\n",
    "datasizes = [[LANGS[lang]]+[len(DATA[lang][crp][0]) \n",
    "                     for crp in ('trn', 'hld', 'dev', 'tst')] \n",
    "             for lang in SMPLS]\n",
    "datasizes = pd.DataFrame.from_records(datasizes, columns=columns)\n",
    "datasizes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -rf $REPO_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdjItmlUpj3k"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qkRzWpGY-fW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM6itzXwQdxPOfAT8T29NOu",
   "include_colab_link": true,
   "name": "LexicalNormalization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
