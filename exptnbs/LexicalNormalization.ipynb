{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pkolachi/lexicalnormalization/blob/master/exptnbs/LexicalNormalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOoroVGYw3Mg"
   },
   "source": [
    "[WNUT21 Shared Task Website](http://noisy-text.github.io/2021/multi-lexnorm.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzRtzY3ApXhe"
   },
   "source": [
    "### Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywhY3ZLXJs0P",
    "outputId": "636b8148-d9c3-4f86-855e-84d73ef71c88"
   },
   "outputs": [],
   "source": [
    "# We no longer clone the github repository. Instead this notebook\n",
    "# is part of the repository itself\n",
    "# !git clone https://github.com/pkolachi/lexicalnormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --user -U pandas==1.1.5\n",
    "# %pip install --user -U scikit-learn==0.22.2.post1\n",
    "# %pip install --user -U sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/lexnorm/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import itertools as it\n",
    "import os.path\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    RepeatedKFold,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GTkdFPXmKBCH"
   },
   "outputs": [],
   "source": [
    "REPO_NAME = \"multilexnorm\"\n",
    "LANGS = {\n",
    "    \"da\": \"Danish\",\n",
    "    \"en\": \"English\",\n",
    "    \"es\": \"Spanish\",\n",
    "    \"hr\": \"Croatian\",\n",
    "    \"iden\": \"Indonesian-English\",\n",
    "    \"it\": \"Italian\",\n",
    "    \"nl\": \"Dutch\",\n",
    "    \"sl\": \"Slovenian\",\n",
    "    \"sr\": \"Serbian\",\n",
    "    \"tr\": \"Turkish\",\n",
    "    \"trde\": \"Turkish-German\",\n",
    "}\n",
    "SMPLS = LANGS.keys()\n",
    "EMPTY_TOKEN = \"+-#EMPTOK#-+\"\n",
    "EMPTY_LABEL = \"+-#MERGE#-+\"  #''\n",
    "PAD_TOKEN = \"+-#NULL#-+\"\n",
    "PAD_LABEL = \"+-#DROP#-+\"\n",
    "TST_RATIO = 0.15  # use 15% of training data as held-out data for evaluation\n",
    "CVFOLDS = 4  # use 4-folds for cross-fold training throughout experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSzppLsjpdql"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VTSBr-AMNXzf"
   },
   "outputs": [],
   "source": [
    "def load_data(inpfile, empty_label=\"\"):\n",
    "    with open(inpfile) as inf:\n",
    "        # break lines into sentence blocks\n",
    "        snb = (list(it.takewhile(lambda lne: lne.strip(), inf)) for _ in it.count(1))\n",
    "        # deal with errors in file format especially turkish\n",
    "        snc = it.dropwhile(lambda snt: len(snt) == 0, snb)\n",
    "        # terminate this infinite stream\n",
    "        snd = it.takewhile(lambda snt: len(snt) > 0, snc)\n",
    "        # split into fields\n",
    "        crs = ([t.strip(\"\\n\").split(\"\\t\", 1) for t in s] for s in snd)\n",
    "        if empty_label:\n",
    "            crp = [\n",
    "                [\n",
    "                    (tok[0], tok[1] if len(tok) > 1 and tok[1].strip() else empty_label)\n",
    "                    for tok in sent\n",
    "                ]\n",
    "                for sent in crs\n",
    "            ]\n",
    "        else:\n",
    "            crp = list(crs)\n",
    "        return crp\n",
    "\n",
    "\n",
    "# remove sentences that do not follow the expected format\n",
    "sanitize_crps = lambda sent: all(len(fields) == 2 for fields in sent)\n",
    "# get input from tuple (raw sentences)\n",
    "get_rawtokens = lambda sent: list(map(itemgetter(0), sent))\n",
    "# get output/labels from tuple (normalized sentences)\n",
    "get_nrmtokens = lambda sent: list(map(itemgetter(1), sent))\n",
    "\n",
    "DATA = defaultdict(lambda: defaultdict(lambda: ([], [])))\n",
    "for lang in SMPLS:\n",
    "    datadir = os.path.join(\"..\", REPO_NAME, \"data\", lang)\n",
    "    trnfile = os.path.join(datadir, \"train.norm\")\n",
    "    devfile = os.path.join(datadir, \"dev.norm\")\n",
    "    tstfile = os.path.join(datadir, \"test.norm\")\n",
    "    for dts, dtf in [(\"fulltrn\", trnfile), (\"dev\", devfile), (\"tst\", tstfile)]:\n",
    "        if os.path.isdir(datadir) and os.path.isfile(dtf):\n",
    "            ocrp = list(load_data(dtf, empty_label=EMPTY_LABEL))\n",
    "            # sanitize corpus to make sure\n",
    "            fcrp = list(filter(sanitize_crps, ocrp))\n",
    "            if len(ocrp) != len(fcrp):\n",
    "                print(f\"Removed {len(ocrp) - len(fcrp)} sentences from {dtf}\")\n",
    "            X = list(map(get_rawtokens, fcrp))\n",
    "            Y = list(map(get_nrmtokens, fcrp))\n",
    "            DATA[lang][dts] = (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DkCFpXbrwD5U"
   },
   "outputs": [],
   "source": [
    "# %rm -rf $REPO_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEmm52m_3Gzo"
   },
   "source": [
    "### Data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V4J-9JaRXMOX"
   },
   "outputs": [],
   "source": [
    "for lang in SMPLS:\n",
    "    if \"fulltrn\" in DATA[lang]:\n",
    "        trn_x, hld_x, trn_y, hld_y = train_test_split(\n",
    "            DATA[lang][\"fulltrn\"][0],\n",
    "            DATA[lang][\"fulltrn\"][1],\n",
    "            test_size=TST_RATIO,\n",
    "            random_state=0,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        DATA[lang][\"trn\"] = (trn_x, trn_y)\n",
    "        DATA[lang][\"hld\"] = (hld_x, hld_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "7nz69Y8xwD5U",
    "outputId": "4a0e61cd-140a-4446-800c-a10da5d0f924"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Training</th>\n",
       "      <th>Held-out</th>\n",
       "      <th>Devel</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danish</td>\n",
       "      <td>611</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>2006</td>\n",
       "      <td>354</td>\n",
       "      <td>590</td>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>482</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Croatian</td>\n",
       "      <td>4046</td>\n",
       "      <td>714</td>\n",
       "      <td>1588</td>\n",
       "      <td>1586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indonesian-English</td>\n",
       "      <td>420</td>\n",
       "      <td>75</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Italian</td>\n",
       "      <td>504</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>770</td>\n",
       "      <td>137</td>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Slovenian</td>\n",
       "      <td>3969</td>\n",
       "      <td>701</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Serbian</td>\n",
       "      <td>3517</td>\n",
       "      <td>621</td>\n",
       "      <td>1379</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>484</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Turkish-German</td>\n",
       "      <td>680</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Language  Training  Held-out  Devel  Test\n",
       "0               Danish       611       108      0   181\n",
       "1              English      2006       354    590  1967\n",
       "2              Spanish       482        86      0   531\n",
       "3             Croatian      4046       714   1588  1586\n",
       "4   Indonesian-English       420        75    165   165\n",
       "5              Italian       504        89      0   100\n",
       "6                Dutch       770       137    308   308\n",
       "7            Slovenian      3969       701   1557  1557\n",
       "8              Serbian      3517       621   1379  1377\n",
       "9              Turkish       484        86      0   143\n",
       "10      Turkish-German       680       120      0   229"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"Language\", \"Training\", \"Held-out\", \"Devel\", \"Test\"]\n",
    "datasizes = [\n",
    "    [LANGS[lang]] + [len(DATA[lang][crp][0]) for crp in (\"trn\", \"hld\", \"dev\", \"tst\")]\n",
    "    for lang in SMPLS\n",
    "]\n",
    "datasizes = pd.DataFrame.from_records(datasizes, columns=columns)\n",
    "\n",
    "datasizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "PC8E_x4F3TTu",
    "outputId": "fd2468df-6be4-410d-b0b1-904053b20d49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Training</th>\n",
       "      <th>Held-out</th>\n",
       "      <th>Devel</th>\n",
       "      <th>Test</th>\n",
       "      <th>AllToks#</th>\n",
       "      <th>Vocab#</th>\n",
       "      <th>Labels#</th>\n",
       "      <th>Trn. Vocab#</th>\n",
       "      <th>Trn. Label#</th>\n",
       "      <th>Ood. Vocab%</th>\n",
       "      <th>Ood. Label%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danish</td>\n",
       "      <td>611</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>6119</td>\n",
       "      <td>5638</td>\n",
       "      <td>5223</td>\n",
       "      <td>3454</td>\n",
       "      <td>3182</td>\n",
       "      <td>38.737141</td>\n",
       "      <td>40.723722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>2006</td>\n",
       "      <td>354</td>\n",
       "      <td>590</td>\n",
       "      <td>1967</td>\n",
       "      <td>19647</td>\n",
       "      <td>19237</td>\n",
       "      <td>18365</td>\n",
       "      <td>9589</td>\n",
       "      <td>9130</td>\n",
       "      <td>50.153350</td>\n",
       "      <td>50.737816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>482</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "      <td>5680</td>\n",
       "      <td>5347</td>\n",
       "      <td>4901</td>\n",
       "      <td>2693</td>\n",
       "      <td>2502</td>\n",
       "      <td>49.635310</td>\n",
       "      <td>49.928586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Croatian</td>\n",
       "      <td>4046</td>\n",
       "      <td>714</td>\n",
       "      <td>1588</td>\n",
       "      <td>1586</td>\n",
       "      <td>26964</td>\n",
       "      <td>25091</td>\n",
       "      <td>23201</td>\n",
       "      <td>15137</td>\n",
       "      <td>14359</td>\n",
       "      <td>39.671595</td>\n",
       "      <td>38.795742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indonesian-English</td>\n",
       "      <td>420</td>\n",
       "      <td>75</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>7172</td>\n",
       "      <td>6702</td>\n",
       "      <td>6166</td>\n",
       "      <td>4256</td>\n",
       "      <td>3889</td>\n",
       "      <td>36.496568</td>\n",
       "      <td>37.804087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Italian</td>\n",
       "      <td>504</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>5458</td>\n",
       "      <td>5118</td>\n",
       "      <td>4856</td>\n",
       "      <td>4046</td>\n",
       "      <td>3837</td>\n",
       "      <td>20.945682</td>\n",
       "      <td>21.210873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>770</td>\n",
       "      <td>137</td>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "      <td>9093</td>\n",
       "      <td>7686</td>\n",
       "      <td>6199</td>\n",
       "      <td>3310</td>\n",
       "      <td>2661</td>\n",
       "      <td>56.934686</td>\n",
       "      <td>60.929182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Slovenian</td>\n",
       "      <td>3969</td>\n",
       "      <td>701</td>\n",
       "      <td>1557</td>\n",
       "      <td>1557</td>\n",
       "      <td>20743</td>\n",
       "      <td>18748</td>\n",
       "      <td>16997</td>\n",
       "      <td>11229</td>\n",
       "      <td>10282</td>\n",
       "      <td>40.105611</td>\n",
       "      <td>40.824851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Serbian</td>\n",
       "      <td>3517</td>\n",
       "      <td>621</td>\n",
       "      <td>1379</td>\n",
       "      <td>1377</td>\n",
       "      <td>24236</td>\n",
       "      <td>22188</td>\n",
       "      <td>20559</td>\n",
       "      <td>13705</td>\n",
       "      <td>12910</td>\n",
       "      <td>38.232378</td>\n",
       "      <td>38.508682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>484</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>7056</td>\n",
       "      <td>5265</td>\n",
       "      <td>4815</td>\n",
       "      <td>3780</td>\n",
       "      <td>3507</td>\n",
       "      <td>28.205128</td>\n",
       "      <td>29.636552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Turkish-German</td>\n",
       "      <td>680</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>9460</td>\n",
       "      <td>7303</td>\n",
       "      <td>6746</td>\n",
       "      <td>5513</td>\n",
       "      <td>5193</td>\n",
       "      <td>24.510475</td>\n",
       "      <td>24.488586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Language  Training  Held-out  Devel  Test  AllToks#  Vocab#  \\\n",
       "0               Danish       611       108      0   181      6119    5638   \n",
       "1              English      2006       354    590  1967     19647   19237   \n",
       "2              Spanish       482        86      0   531      5680    5347   \n",
       "3             Croatian      4046       714   1588  1586     26964   25091   \n",
       "4   Indonesian-English       420        75    165   165      7172    6702   \n",
       "5              Italian       504        89      0   100      5458    5118   \n",
       "6                Dutch       770       137    308   308      9093    7686   \n",
       "7            Slovenian      3969       701   1557  1557     20743   18748   \n",
       "8              Serbian      3517       621   1379  1377     24236   22188   \n",
       "9              Turkish       484        86      0   143      7056    5265   \n",
       "10      Turkish-German       680       120      0   229      9460    7303   \n",
       "\n",
       "    Labels#  Trn. Vocab#  Trn. Label#  Ood. Vocab%  Ood. Label%  \n",
       "0      5223         3454         3182    38.737141    40.723722  \n",
       "1     18365         9589         9130    50.153350    50.737816  \n",
       "2      4901         2693         2502    49.635310    49.928586  \n",
       "3     23201        15137        14359    39.671595    38.795742  \n",
       "4      6166         4256         3889    36.496568    37.804087  \n",
       "5      4856         4046         3837    20.945682    21.210873  \n",
       "6      6199         3310         2661    56.934686    60.929182  \n",
       "7     16997        11229        10282    40.105611    40.824851  \n",
       "8     20559        13705        12910    38.232378    38.508682  \n",
       "9      4815         3780         3507    28.205128    29.636552  \n",
       "10     6746         5513         5193    24.510475    24.488586  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasizes[\"AllToks#\"] = [\n",
    "    len(\n",
    "        {\n",
    "            tok\n",
    "            for dts in (\"trn\", \"hld\", \"dev\", \"tst\")\n",
    "            for typ in (0, 1)\n",
    "            for sent in DATA[lang][dts][typ]\n",
    "            for tok in sent\n",
    "        }\n",
    "    )\n",
    "    for lang in SMPLS\n",
    "]\n",
    "\n",
    "datasizes[\"Vocab#\"] = [\n",
    "    len(\n",
    "        {\n",
    "            tok\n",
    "            for dts in (\"trn\", \"hld\", \"dev\", \"tst\")\n",
    "            for sent in DATA[lang][dts][0]\n",
    "            for tok in sent\n",
    "        }\n",
    "    )\n",
    "    for lang in SMPLS\n",
    "]\n",
    "datasizes[\"Labels#\"] = [\n",
    "    len(\n",
    "        {\n",
    "            tok\n",
    "            for dts in (\"trn\", \"hld\", \"dev\", \"tst\")\n",
    "            for sent in DATA[lang][dts][1]\n",
    "            for tok in sent\n",
    "        }\n",
    "    )\n",
    "    for lang in SMPLS\n",
    "]\n",
    "\n",
    "datasizes[\"Trn. Vocab#\"] = [\n",
    "    len({tok for sent in DATA[lang][\"trn\"][0] for tok in sent}) for lang in SMPLS\n",
    "]\n",
    "datasizes[\"Trn. Label#\"] = [\n",
    "    len({tok for sent in DATA[lang][\"trn\"][1] for tok in sent}) for lang in SMPLS\n",
    "]\n",
    "\n",
    "datasizes[\"Ood. Vocab%\"] = [\n",
    "    len(\n",
    "        {\n",
    "            tok\n",
    "            for dts in (\"hld\", \"dev\", \"tst\")\n",
    "            for sent in DATA[lang][dts][0]\n",
    "            for tok in sent\n",
    "        }.difference({tok for sent in DATA[lang][\"trn\"][0] for tok in sent})\n",
    "    )\n",
    "    for lang in SMPLS\n",
    "]\n",
    "datasizes[\"Ood. Label%\"] = [\n",
    "    len(\n",
    "        {\n",
    "            tok\n",
    "            for dts in (\"hld\", \"dev\", \"tst\")\n",
    "            for sent in DATA[lang][dts][1]\n",
    "            for tok in sent\n",
    "        }.difference({tok for sent in DATA[lang][\"trn\"][0] for tok in sent})\n",
    "    )\n",
    "    for lang in SMPLS\n",
    "]\n",
    "datasizes[\"Ood. Vocab%\"] = 100 * datasizes[\"Ood. Vocab%\"] / datasizes[\"Vocab#\"]\n",
    "datasizes[\"Ood. Label%\"] = 100 * datasizes[\"Ood. Label%\"] / datasizes[\"Labels#\"]\n",
    "\n",
    "datasizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRbS1VJ396r2"
   },
   "source": [
    "### Task Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "omrn2mZv7bT9"
   },
   "outputs": [],
   "source": [
    "FOLDS = defaultdict(list)\n",
    "kcvs = RepeatedKFold(n_splits=CVFOLDS, n_repeats=5, random_state=0)\n",
    "for lang in SMPLS:\n",
    "    FOLDS[lang].extend(kcvs.split(DATA[lang][\"trn\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LwPn_NHdKG6g"
   },
   "outputs": [],
   "source": [
    "# Leave-As-Is i.e. return input as output\n",
    "class LAI(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, pad_tok=PAD_TOKEN, pad_lbl=PAD_LABEL):\n",
    "        self.__pad_tok = pad_tok\n",
    "        self.__pad_lbl = pad_lbl\n",
    "        self.__scores = defaultdict(float)\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        max_len = max(it.chain((len(seq) for seq in X), (len(seq) for seq in Y)))\n",
    "        # X = np.asarray([seq + [self.__pad_tok]*(max_len-len(seq)) for seq in X], dtype=str)\n",
    "        # Y = np.asarray([seq + [self.__pad_lbl]*(max_len-len(seq)) for seq in Y], dtype=str)\n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        max_len = max(len(seq) for seq in X)\n",
    "        # X = np.asarray([seq + [self.__pad_tok]*(max_len-len(seq)) for seq in X], dtype=str)\n",
    "        return X\n",
    "\n",
    "    def score(self, X, Y, ignoreCase=False):\n",
    "        prdY = self.predict(X)\n",
    "        zipS = ((inp, out, oup) for inp, out, oup in zip(X, Y, prdY))\n",
    "        # eliminate instances if lengths do not match\n",
    "        zipF = (seq for seq in zipS if len(seq[1]) == len(seq[2]))\n",
    "        tokS = ((rawW, gldW, prdW) for seq in zipF for rawW, gldW, prdW in zip(*seq))\n",
    "        correct, changed, total = 0, 0, 0\n",
    "        for rawW, gldW, prdW in tokS:\n",
    "            total += 1\n",
    "            if ignoreCase:\n",
    "                rawW = rawW.lower()\n",
    "                gldW = gldW.lower()\n",
    "                prdW = prdW.lower()\n",
    "            if rawW != gldW:\n",
    "                changed += 1\n",
    "            if gldW == prdW:\n",
    "                correct += 1\n",
    "        # evaluation used in the shared task\n",
    "        self.__scores[\"accuracy\"] = correct / total\n",
    "        self.__scores[\"lai\"] = (total - changed) / total\n",
    "        if self.__scores[\"lai\"] == 1:\n",
    "            self.__scores[\"err\"] = 0\n",
    "        else:\n",
    "            self.__scores[\"err\"] = (\n",
    "                self.__scores[\"accuracy\"] - self.__scores[\"lai\"]\n",
    "            ) / (1 - self.__scores[\"lai\"])\n",
    "        return self.__scores[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tTZOImW997A-"
   },
   "outputs": [],
   "source": [
    "# Most-Frequent-Replacement\n",
    "class MFR(LAI):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.__counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        super().fit(X, Y)\n",
    "        replacements = (\n",
    "            (itok, otok) for iseg, oseg in zip(X, Y) for itok, otok in zip(iseg, oseg)\n",
    "        )\n",
    "        for inp, rpl in replacements:\n",
    "            self.__counts[inp][rpl] += 1\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = super().predict(X)\n",
    "        prdY = []\n",
    "        for iseg in X:\n",
    "            oseg = []\n",
    "            for itok in iseg:\n",
    "                lns = self.__counts[itok]\n",
    "                if len(lns) == 0:\n",
    "                    oseg.append(itok)\n",
    "                else:\n",
    "                    oseg.append(sorted(lns.items(), key=itemgetter(1))[0][0])\n",
    "            prdY.append(oseg)\n",
    "        return prdY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFV_O4WAFRoM",
    "outputId": "dc215fa1-9c58-441c-e223-1309e3ae23fb"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LAI' object has no attribute 'pad_lbl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lexnorm/lib/python3.9/site-packages/joblib/parallel.py:822\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m queue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;66;03m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;66;03m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;66;03m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lexnorm/lib/python3.9/queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m SMPLS:\n\u001b[0;32m----> 2\u001b[0m     cvres \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDATA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDATA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFOLDS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(lang, \u001b[38;5;28msum\u001b[39m(acc \u001b[38;5;28;01mfor\u001b[39;00m acc \u001b[38;5;129;01min\u001b[39;00m cvres[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(cvres[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lexnorm/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 267\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lexnorm/lib/python3.9/site-packages/joblib/parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lexnorm/lib/python3.9/site-packages/joblib/parallel.py:833\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    830\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_effective_n_jobs\n\u001b[1;32m    831\u001b[0m big_batch_size \u001b[38;5;241m=\u001b[39m batch_size \u001b[38;5;241m*\u001b[39m n_jobs\n\u001b[0;32m--> 833\u001b[0m islice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbig_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(islice) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lexnorm/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:269\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    267\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    268\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m--> 269\u001b[0m         \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    270\u001b[0m         X,\n\u001b[1;32m    271\u001b[0m         y,\n\u001b[1;32m    272\u001b[0m         scorers,\n\u001b[1;32m    273\u001b[0m         train,\n\u001b[1;32m    274\u001b[0m         test,\n\u001b[1;32m    275\u001b[0m         verbose,\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    277\u001b[0m         fit_params,\n\u001b[1;32m    278\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    279\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    280\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    281\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    286\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lexnorm/lib/python3.9/site-packages/sklearn/base.py:84\u001b[0m, in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit does not seem to be a scikit-learn \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator as it does not implement a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(estimator), \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[1;32m     81\u001b[0m             )\n\u001b[1;32m     83\u001b[0m klass \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[0;32m---> 84\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m new_object_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     86\u001b[0m     new_object_params[name] \u001b[38;5;241m=\u001b[39m clone(param, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/lexnorm/lib/python3.9/site-packages/sklearn/base.py:210\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    208\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[0;32m--> 210\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    212\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LAI' object has no attribute 'pad_lbl'"
     ]
    }
   ],
   "source": [
    "for lang in SMPLS:\n",
    "    cvres = cross_validate(\n",
    "        LAI(),\n",
    "        DATA[lang][\"trn\"][0],\n",
    "        DATA[lang][\"trn\"][1],\n",
    "        cv=FOLDS[lang],\n",
    "        return_train_score=True,\n",
    "    )\n",
    "    print(lang, sum(acc for acc in cvres[\"test_score\"]) / len(cvres[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZUyx0JVEMnj"
   },
   "source": [
    "### Sequence classification using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdjItmlUpj3k"
   },
   "source": [
    "##### Preprocessing\n",
    "\n",
    "In this step, we convert the sequence of tokens into an embedding matrix. \n",
    "This step relies on tokenizers and pre-trained models from ``huggingface``.\n",
    "This seperation of preprocessing should allow for training other classifiers \n",
    "than neural versions using ``scikit-learn`` or other packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qkRzWpGY-fW"
   },
   "outputs": [],
   "source": [
    "for lang in SMPLS:\n",
    "    # load tokenizer model from ``huggingface``\n",
    "    for dts in DATA[lang]:\n",
    "        for inp, out in zip(DATA[lang][dts][0], DATA[lang][dts][1]):\n",
    "            tinp = []\n",
    "            tout = []\n",
    "            for intok, outok in zip(inp, out):\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0rYO-eeEMy-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5arwc2T385K"
   },
   "source": [
    "### Sequence classification using HMM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtNuRD1539GR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "LexicalNormalization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:lexnorm]",
   "language": "python",
   "name": "conda-env-lexnorm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
