{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pkolachi/lexicalnormalization/blob/master/exptnbs/LexicalNormalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOoroVGYw3Mg"
   },
   "source": [
    "[WNUT21 Shared Task Website](http://noisy-text.github.io/2021/multi-lexnorm.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzRtzY3ApXhe"
   },
   "source": [
    "### Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywhY3ZLXJs0P",
    "outputId": "5400a694-1b2f-4c53-b252-86aaadd7c2cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'lexicalnormalization'...\n",
      "remote: Enumerating objects: 88, done.\u001b[K\n",
      "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
      "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
      "remote: Total 88 (delta 12), reused 54 (delta 3), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (88/88), 1.41 MiB | 2.69 MiB/s, done.\n",
      "Requirement already up-to-date: pandas==1.1.5 in /home/pkolachi/.local/lib/python3.8/site-packages (1.1.5)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /home/pkolachi/.local/lib/python3.8/site-packages (from pandas==1.1.5) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /home/pkolachi/.local/lib/python3.8/site-packages (from pandas==1.1.5) (1.19.4)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas==1.1.5) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/pkolachi/.local/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already up-to-date: scikit-learn==0.22.2.post1 in /home/pkolachi/.local/lib/python3.8/site-packages (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/pkolachi/.local/lib/python3.8/site-packages (from scikit-learn==0.22.2.post1) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /home/pkolachi/.local/lib/python3.8/site-packages (from scikit-learn==0.22.2.post1) (1.19.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /home/pkolachi/.local/lib/python3.8/site-packages (from scikit-learn==0.22.2.post1) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already up-to-date: sklearn-crfsuite in /home/pkolachi/.local/lib/python3.8/site-packages (0.3.6)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=2.0 in /home/pkolachi/.local/lib/python3.8/site-packages (from sklearn-crfsuite) (4.53.0)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in /home/pkolachi/.local/lib/python3.8/site-packages (from sklearn-crfsuite) (0.8.9)\n",
      "Requirement already satisfied, skipping upgrade: python-crfsuite>=0.8.3 in /home/pkolachi/.local/lib/python3.8/site-packages (from sklearn-crfsuite) (0.9.7)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/pkolachi/.local/lib/python3.8/site-packages (from sklearn-crfsuite) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pkolachi/lexicalnormalization\n",
    "%pip install --user -U pandas==1.1.5\n",
    "%pip install --user -U scikit-learn==0.22.2.post1\n",
    "%pip install --user -U sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GTkdFPXmKBCH"
   },
   "outputs": [],
   "source": [
    "REPO_NAME = 'lexicalnormalization'\n",
    "LANGS = {'da': 'Danish',\n",
    "         'en': 'English',\n",
    "         'es': 'Spanish',\n",
    "         'hr': 'Croatian',\n",
    "         'iden': 'Indonesian-English',\n",
    "         'it': 'Italian',\n",
    "         'nl': 'Dutch',\n",
    "         'sl': 'Slovenian',\n",
    "         'sr': 'Serbian',\n",
    "         'tr': 'Turkish',\n",
    "         'trde': 'Turkish-German',\n",
    "         }\n",
    "SMPLS = LANGS.keys()\n",
    "EMPTY_LABEL = '+-#MERGE#-+' #''\n",
    "PAD_LABEL   = '+-#DROP#-+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSzppLsjpdql"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTSBr-AMNXzf",
    "outputId": "cc0129f2-82a3-4021-dab6-ab038379b762"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "import itertools as it \n",
    "from operator import itemgetter\n",
    "import os.path \n",
    "import pandas as pd\n",
    "\n",
    "def load_data(inpfile, empty_label=''):\n",
    "  with open(inpfile) as inf:\n",
    "    # break lines into sentence blocks\n",
    "    snb = (list(it.takewhile(lambda lne: lne.strip(), inf)) for _ in it.count(1))\n",
    "    # deal with errors in file format especially turkish\n",
    "    snc = it.dropwhile(lambda snt: len(snt) == 0, snb)\n",
    "    # terminate this infinite stream \n",
    "    snd = it.takewhile(lambda snt: len(snt)  > 0, snc)\n",
    "    # split into fields\n",
    "    crs = ([t.strip('\\n').split('\\t', 1) for t in s] for s in snd)\n",
    "    if empty_label:\n",
    "      crp = [[(tok[0], tok[1] if len(tok) > 1 and tok[1].strip() else empty_label)\n",
    "              for tok in sent]\n",
    "             for sent in crs]\n",
    "    else:\n",
    "      crp = list(crs)\n",
    "    return crp\n",
    "\n",
    "# remove sentences that do not follow the expected format\n",
    "sanitize_crps = lambda sent: all(len(fields) == 2 for fields in sent)\n",
    "# get input from tuple (raw sentences)\n",
    "get_rawtokens = lambda sent: list(map(itemgetter(0), sent)) \n",
    "# get output/labels from tuple (normalized sentences)\n",
    "get_nrmtokens = lambda sent: list(map(itemgetter(1), sent))\n",
    "\n",
    "DATA = defaultdict(lambda: defaultdict(lambda: ([], [])))\n",
    "for lang in SMPLS:\n",
    "  datadir = os.path.join(REPO_NAME, 'data', lang)\n",
    "  trnfile = os.path.join(datadir, 'train.norm')\n",
    "  devfile = os.path.join(datadir, 'dev.norm')\n",
    "  tstfile = os.path.join(datadir, 'test.norm')\n",
    "  for dts, dtf in [('fulltrn', trnfile), ('dev', devfile), ('tst', tstfile)]:\n",
    "    if os.path.isdir(datadir) and os.path.isfile(dtf):\n",
    "      ocrp = list(load_data(dtf, empty_label=EMPTY_LABEL))\n",
    "      # sanitize corpus to make sure\n",
    "      fcrp = list(filter(sanitize_crps, ocrp))\n",
    "      if len(ocrp) != len(fcrp): print(\"Removed {0} sentences from {1}\".format(len(ocrp)-len(fcrp), dtf))\n",
    "      X = list(map(get_rawtokens, fcrp))  \n",
    "      Y = list(map(get_nrmtokens, fcrp))\n",
    "      DATA[lang][dts] = (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DkCFpXbrwD5U"
   },
   "outputs": [],
   "source": [
    "%rm -rf $REPO_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEmm52m_3Gzo"
   },
   "source": [
    "### Data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V4J-9JaRXMOX"
   },
   "outputs": [],
   "source": [
    "TST_RATIO = 0.15\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "for lang in SMPLS:\n",
    "  if 'fulltrn' in DATA[lang]:\n",
    "    trn_x, hld_x, trn_y, hld_y = train_test_split(DATA[lang]['fulltrn'][0], \n",
    "                                                  DATA[lang]['fulltrn'][1], \n",
    "                                                  test_size=TST_RATIO, \n",
    "                                                  random_state=0, \n",
    "                                                  shuffle=False)\n",
    "    DATA[lang]['trn'] = (trn_x, trn_y)\n",
    "    DATA[lang]['hld'] = (hld_x, hld_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "7nz69Y8xwD5U",
    "outputId": "aaac7e0e-35c3-4ca9-bef1-4f31b7731542"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Training</th>\n",
       "      <th>Held-out</th>\n",
       "      <th>Devel</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danish</td>\n",
       "      <td>175</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>2006</td>\n",
       "      <td>354</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>482</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Croatian</td>\n",
       "      <td>381</td>\n",
       "      <td>68</td>\n",
       "      <td>1588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indonesian-English</td>\n",
       "      <td>420</td>\n",
       "      <td>75</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Italian</td>\n",
       "      <td>504</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>798</td>\n",
       "      <td>141</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Slovenian</td>\n",
       "      <td>3969</td>\n",
       "      <td>701</td>\n",
       "      <td>1557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Serbian</td>\n",
       "      <td>3517</td>\n",
       "      <td>621</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>484</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Turkish-German</td>\n",
       "      <td>680</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Language  Training  Held-out  Devel  Test\n",
       "0               Danish       175        32      0     0\n",
       "1              English      2006       354    590     0\n",
       "2              Spanish       482        86      0     0\n",
       "3             Croatian       381        68   1588     0\n",
       "4   Indonesian-English       420        75    165     0\n",
       "5              Italian       504        89      0     0\n",
       "6                Dutch       798       141    314     0\n",
       "7            Slovenian      3969       701   1557     0\n",
       "8              Serbian      3517       621   1327     0\n",
       "9              Turkish       484        86      0     0\n",
       "10      Turkish-German       680       120      0     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Language', 'Training', 'Held-out', 'Devel', 'Test']\n",
    "datasizes = [[LANGS[lang]]+[len(DATA[lang][crp][0]) \n",
    "                     for crp in ('trn', 'hld', 'dev', 'tst')] \n",
    "             for lang in SMPLS]\n",
    "datasizes = pd.DataFrame.from_records(datasizes, columns=columns)\n",
    "\n",
    "datasizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "PC8E_x4F3TTu",
    "outputId": "f72c631a-6be6-4ded-873d-87a5aa334698"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Training</th>\n",
       "      <th>Held-out</th>\n",
       "      <th>Devel</th>\n",
       "      <th>Test</th>\n",
       "      <th>AllToks#</th>\n",
       "      <th>Vocab#</th>\n",
       "      <th>Labels#</th>\n",
       "      <th>Trn. Vocab#</th>\n",
       "      <th>Trn. Label#</th>\n",
       "      <th>Ood. Vocab%</th>\n",
       "      <th>Ood. Label%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danish</td>\n",
       "      <td>175</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3421</td>\n",
       "      <td>3333</td>\n",
       "      <td>3280</td>\n",
       "      <td>2935</td>\n",
       "      <td>2886</td>\n",
       "      <td>11.941194</td>\n",
       "      <td>12.195122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>2006</td>\n",
       "      <td>354</td>\n",
       "      <td>590</td>\n",
       "      <td>0</td>\n",
       "      <td>13437</td>\n",
       "      <td>13127</td>\n",
       "      <td>12521</td>\n",
       "      <td>9589</td>\n",
       "      <td>9130</td>\n",
       "      <td>26.952083</td>\n",
       "      <td>27.561696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>482</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3285</td>\n",
       "      <td>3064</td>\n",
       "      <td>2833</td>\n",
       "      <td>2695</td>\n",
       "      <td>2504</td>\n",
       "      <td>12.043081</td>\n",
       "      <td>12.072008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Croatian</td>\n",
       "      <td>381</td>\n",
       "      <td>68</td>\n",
       "      <td>1588</td>\n",
       "      <td>0</td>\n",
       "      <td>9609</td>\n",
       "      <td>8886</td>\n",
       "      <td>8434</td>\n",
       "      <td>2110</td>\n",
       "      <td>2085</td>\n",
       "      <td>76.254783</td>\n",
       "      <td>75.492056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indonesian-English</td>\n",
       "      <td>420</td>\n",
       "      <td>75</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>6185</td>\n",
       "      <td>5754</td>\n",
       "      <td>5284</td>\n",
       "      <td>4256</td>\n",
       "      <td>3887</td>\n",
       "      <td>26.034063</td>\n",
       "      <td>27.346707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Italian</td>\n",
       "      <td>504</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4941</td>\n",
       "      <td>4619</td>\n",
       "      <td>4383</td>\n",
       "      <td>4046</td>\n",
       "      <td>3836</td>\n",
       "      <td>12.405283</td>\n",
       "      <td>12.616929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>798</td>\n",
       "      <td>141</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>7885</td>\n",
       "      <td>6651</td>\n",
       "      <td>5394</td>\n",
       "      <td>3591</td>\n",
       "      <td>2902</td>\n",
       "      <td>46.008119</td>\n",
       "      <td>49.536522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Slovenian</td>\n",
       "      <td>3969</td>\n",
       "      <td>701</td>\n",
       "      <td>1557</td>\n",
       "      <td>0</td>\n",
       "      <td>17673</td>\n",
       "      <td>15963</td>\n",
       "      <td>14501</td>\n",
       "      <td>11229</td>\n",
       "      <td>10276</td>\n",
       "      <td>29.656080</td>\n",
       "      <td>30.315151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Serbian</td>\n",
       "      <td>3517</td>\n",
       "      <td>621</td>\n",
       "      <td>1327</td>\n",
       "      <td>0</td>\n",
       "      <td>20385</td>\n",
       "      <td>18658</td>\n",
       "      <td>17443</td>\n",
       "      <td>13705</td>\n",
       "      <td>12912</td>\n",
       "      <td>26.546254</td>\n",
       "      <td>27.019435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Turkish</td>\n",
       "      <td>484</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5837</td>\n",
       "      <td>4326</td>\n",
       "      <td>3992</td>\n",
       "      <td>3760</td>\n",
       "      <td>3501</td>\n",
       "      <td>13.083680</td>\n",
       "      <td>13.677355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Turkish-German</td>\n",
       "      <td>680</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7856</td>\n",
       "      <td>6156</td>\n",
       "      <td>5752</td>\n",
       "      <td>5514</td>\n",
       "      <td>5194</td>\n",
       "      <td>10.428850</td>\n",
       "      <td>10.639777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Language  Training  Held-out  Devel  Test  AllToks#  Vocab#  \\\n",
       "0               Danish       175        32      0     0      3421    3333   \n",
       "1              English      2006       354    590     0     13437   13127   \n",
       "2              Spanish       482        86      0     0      3285    3064   \n",
       "3             Croatian       381        68   1588     0      9609    8886   \n",
       "4   Indonesian-English       420        75    165     0      6185    5754   \n",
       "5              Italian       504        89      0     0      4941    4619   \n",
       "6                Dutch       798       141    314     0      7885    6651   \n",
       "7            Slovenian      3969       701   1557     0     17673   15963   \n",
       "8              Serbian      3517       621   1327     0     20385   18658   \n",
       "9              Turkish       484        86      0     0      5837    4326   \n",
       "10      Turkish-German       680       120      0     0      7856    6156   \n",
       "\n",
       "    Labels#  Trn. Vocab#  Trn. Label#  Ood. Vocab%  Ood. Label%  \n",
       "0      3280         2935         2886    11.941194    12.195122  \n",
       "1     12521         9589         9130    26.952083    27.561696  \n",
       "2      2833         2695         2504    12.043081    12.072008  \n",
       "3      8434         2110         2085    76.254783    75.492056  \n",
       "4      5284         4256         3887    26.034063    27.346707  \n",
       "5      4383         4046         3836    12.405283    12.616929  \n",
       "6      5394         3591         2902    46.008119    49.536522  \n",
       "7     14501        11229        10276    29.656080    30.315151  \n",
       "8     17443        13705        12912    26.546254    27.019435  \n",
       "9      3992         3760         3501    13.083680    13.677355  \n",
       "10     5752         5514         5194    10.428850    10.639777  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasizes['AllToks#'] = [len(set(tok for dts in ('trn', 'hld', 'dev', 'tst')\n",
    "                                 for typ in (0, 1)\n",
    "                                 for sent in DATA[lang][dts][typ]\n",
    "                                 for tok in sent)) for lang in SMPLS]\n",
    "\n",
    "datasizes['Vocab#']  = [len(set(tok for dts in ('trn', 'hld', 'dev', 'tst')\n",
    "                                for sent in DATA[lang][dts][0] for tok in sent))\n",
    "                        for lang in SMPLS]\n",
    "datasizes['Labels#'] = [len(set(tok for dts in ('trn', 'hld', 'dev', 'tst')\n",
    "                                for sent in DATA[lang][dts][1] for tok in sent))\n",
    "                        for lang in SMPLS]\n",
    "\n",
    "datasizes['Trn. Vocab#'] = [len(set(tok for sent in DATA[lang]['trn'][0]\n",
    "                                    for tok in sent)) for lang in SMPLS]\n",
    "datasizes['Trn. Label#'] = [len(set(tok for sent in DATA[lang]['trn'][1]\n",
    "                                    for tok in sent)) for lang in SMPLS]\n",
    "\n",
    "datasizes['Ood. Vocab%'] = [len(set(tok for dts in ('hld', 'dev', 'tst')\n",
    "                                    for sent in DATA[lang][dts][0]\n",
    "                                    for tok in sent).difference(\n",
    "                                        set(tok for sent in DATA[lang]['trn'][0]\n",
    "                                            for tok in sent)\n",
    "                                        )) for lang in SMPLS]\n",
    "datasizes['Ood. Label%'] = [len(set(tok for dts in ('hld', 'dev', 'tst')\n",
    "                                    for sent in DATA[lang][dts][1]\n",
    "                                    for tok in sent).difference(\n",
    "                                        set(tok for sent in DATA[lang]['trn'][0]\n",
    "                                            for tok in sent)\n",
    "                                        )) for lang in SMPLS]\n",
    "datasizes['Ood. Vocab%'] = 100 * datasizes['Ood. Vocab%'] / datasizes['Vocab#']\n",
    "datasizes['Ood. Label%'] = 100 * datasizes['Ood. Label%'] / datasizes['Labels#']\n",
    "\n",
    "datasizes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZUyx0JVEMnj"
   },
   "source": [
    "### Sequence classification using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdjItmlUpj3k"
   },
   "source": [
    "##### Preprocessing\n",
    "\n",
    "In this step, we convert the sequence of tokens into an embedding matrix. \n",
    "This step relies on tokenizers and pre-trained models from ``huggingface``.\n",
    "This seperation of preprocessing should allow for training other classifiers \n",
    "than neural versions using ``scikit-learn`` or other packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7qkRzWpGY-fW"
   },
   "outputs": [],
   "source": [
    "for lang in SMPLS:\n",
    "  # load tokenizer model from ``huggingface``\n",
    "  for dts in DATA[lang]:\n",
    "    for inp, out in zip(DATA[lang][dts][0], DATA[lang][dts][1]):\n",
    "      tinp = []\n",
    "      tout = []\n",
    "      for intok, outok in zip(inp, out):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0rYO-eeEMy-"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5arwc2T385K"
   },
   "source": [
    "### Sequence classification using HMM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtNuRD1539GR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "LexicalNormalization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
