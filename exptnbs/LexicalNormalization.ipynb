{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LexicalNormalization.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkolachi/lexicalnormalization/blob/master/exptnbs/LexicalNormalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOoroVGYw3Mg"
      },
      "source": [
        "[WNUT21 Shared Task Website](http://noisy-text.github.io/2021/multi-lexnorm.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzRtzY3ApXhe"
      },
      "source": [
        "### Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywhY3ZLXJs0P",
        "outputId": "7f8082cb-eb32-4dfb-f42e-df1f710f9bb0"
      },
      "source": [
        "!git clone https://github.com/pkolachi/lexicalnormalization\n",
        "%pip install --user -U pandas==1.1.5\n",
        "%pip install --user -U scikit-learn==0.22.2.post1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'lexicalnormalization'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 80 (delta 10), reused 54 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (80/80), done.\n",
            "Requirement already up-to-date: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.5) (1.15.0)\n",
            "Requirement already up-to-date: scikit-learn==0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2.post1) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2.post1) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2.post1) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTkdFPXmKBCH"
      },
      "source": [
        "REPO_NAME = 'lexicalnormalization'\n",
        "LANGS = {'da': 'Danish',\n",
        "         'en': 'English',\n",
        "         'es': 'Spanish',\n",
        "         'hr': 'Croatian',\n",
        "         'iden': 'Indonesian-English',\n",
        "         'it': 'Italian',\n",
        "         'nl': 'Dutch',\n",
        "         'sl': 'Slovenian',\n",
        "         'sr': 'Serbian',\n",
        "         'tr': 'Turkish',\n",
        "         'trde': 'Turkish-German',\n",
        "         }\n",
        "SMPLS = LANGS.keys()\n",
        "EMPTY_LABEL = '+-#MERGE#-+' #''\n",
        "PAD_LABEL   = '+-#DROP#-+'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSzppLsjpdql"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTSBr-AMNXzf",
        "outputId": "5fbb0737-1e2e-4fda-db6f-c24e82240874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from collections import defaultdict \n",
        "from operator import itemgetter\n",
        "import os.path \n",
        "import pandas as pd\n",
        "\n",
        "def load_data(inpfile, empty_label=''): \n",
        "  with open(inpfile) as ins:\n",
        "    sent = []\n",
        "    for lne in ins:\n",
        "      if not lne.strip():\n",
        "        yield sent\n",
        "        sent = []\n",
        "      else:\n",
        "        fields = tuple(lne.strip('\\n').split('\\t', 1))\n",
        "        if len(fields) > 1 and not fields[1].strip() and empty_label:\n",
        "          fields = (fields[0], empty_label)\n",
        "        sent.append(fields)\n",
        "    # this shouldn't be necessary if the files are correctly formatted\n",
        "    # but if EOF is encountered without a blank line at the end\n",
        "    if len(sent):\n",
        "      yield sent\n",
        "      sent = []\n",
        "\n",
        "# remove sentences that do not follow the expected format\n",
        "sanitize_crps = lambda sent: all(len(fields) == 2 for fields in sent)\n",
        "# get input from tuple (raw sentences)\n",
        "get_rawtokens = lambda sent: list(map(itemgetter(0), sent)) \n",
        "# get output/labels from tuple (normalized sentences)\n",
        "get_nrmtokens = lambda sent: list(map(itemgetter(1), sent))\n",
        "\n",
        "DATA = defaultdict(lambda: defaultdict(lambda: ([], [])))\n",
        "for lang in SMPLS:\n",
        "  datadir = os.path.join(REPO_NAME, 'data', lang)\n",
        "  trnfile = os.path.join(datadir, 'train.norm')\n",
        "  devfile = os.path.join(datadir, 'dev.norm')\n",
        "  tstfile = os.path.join(datadir, 'test.norm')\n",
        "  for dts, dtf in [('fulltrn', trnfile), ('dev', devfile), ('tst', tstfile)]:\n",
        "    if os.path.isdir(datadir) and os.path.isfile(dtf):\n",
        "      ocrp = list(load_data(dtf, empty_label=EMPTY_LABEL))\n",
        "      # sanitize corpus to make sure\n",
        "      fcrp = list(filter(sanitize_crps, ocrp))\n",
        "      if len(ocrp) != len(fcrp): print(\"Removed {0} sentences from {1}\".format(len(ocrp)-len(fcrp), dtf))\n",
        "      X = list(map(get_rawtokens, fcrp))  \n",
        "      Y = list(map(get_nrmtokens, fcrp)) \n",
        "      DATA[lang][dts] = (X, Y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removed 1 sentences from lexicalnormalization/data/nl/train.norm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkCFpXbrwD5U"
      },
      "source": [
        "%rm -rf $REPO_NAME"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEmm52m_3Gzo"
      },
      "source": [
        "### Data statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4J-9JaRXMOX"
      },
      "source": [
        "TST_RATIO = 0.15\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "for lang in SMPLS:\n",
        "  if 'fulltrn' in DATA[lang]:\n",
        "    trn_x, hld_x, trn_y, hld_y = train_test_split(DATA[lang]['fulltrn'][0], \n",
        "                                                  DATA[lang]['fulltrn'][1], \n",
        "                                                  test_size=TST_RATIO, \n",
        "                                                  random_state=0, \n",
        "                                                  shuffle=False)\n",
        "    DATA[lang]['trn'] = (trn_x, trn_y)\n",
        "    DATA[lang]['hld'] = (hld_x, hld_y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "7nz69Y8xwD5U",
        "outputId": "f2dc31c6-ed7c-491d-e078-3fb67a7cac81"
      },
      "source": [
        "columns = ['Language', 'Training', 'Held-out', 'Devel', 'Test']\n",
        "datasizes = [[LANGS[lang]]+[len(DATA[lang][crp][0]) \n",
        "                     for crp in ('trn', 'hld', 'dev', 'tst')] \n",
        "             for lang in SMPLS]\n",
        "datasizes = pd.DataFrame.from_records(datasizes, columns=columns)\n",
        "\n",
        "datasizes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Language</th>\n",
              "      <th>Training</th>\n",
              "      <th>Held-out</th>\n",
              "      <th>Devel</th>\n",
              "      <th>Test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Danish</td>\n",
              "      <td>175</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>English</td>\n",
              "      <td>2006</td>\n",
              "      <td>354</td>\n",
              "      <td>590</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spanish</td>\n",
              "      <td>482</td>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Croatian</td>\n",
              "      <td>4049</td>\n",
              "      <td>715</td>\n",
              "      <td>1588</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Indonesian-English</td>\n",
              "      <td>420</td>\n",
              "      <td>75</td>\n",
              "      <td>165</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Italian</td>\n",
              "      <td>504</td>\n",
              "      <td>89</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Dutch</td>\n",
              "      <td>797</td>\n",
              "      <td>141</td>\n",
              "      <td>314</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Slovenian</td>\n",
              "      <td>3969</td>\n",
              "      <td>701</td>\n",
              "      <td>1557</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Serbian</td>\n",
              "      <td>3517</td>\n",
              "      <td>621</td>\n",
              "      <td>1381</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Turkish</td>\n",
              "      <td>486</td>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Turkish-German</td>\n",
              "      <td>680</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Language  Training  Held-out  Devel  Test\n",
              "0               Danish       175        32      0     0\n",
              "1              English      2006       354    590     0\n",
              "2              Spanish       482        86      0     0\n",
              "3             Croatian      4049       715   1588     0\n",
              "4   Indonesian-English       420        75    165     0\n",
              "5              Italian       504        89      0     0\n",
              "6                Dutch       797       141    314     0\n",
              "7            Slovenian      3969       701   1557     0\n",
              "8              Serbian      3517       621   1381     0\n",
              "9              Turkish       486        86      0     0\n",
              "10      Turkish-German       680       120      0     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC8E_x4F3TTu",
        "outputId": "860fa8a2-5fea-4757-b659-f7e0814bcce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "datasizes['AllToks#'] = [len(set(tok for dts in ('trn', 'hld', 'dev', 'tst')\n",
        "                                 for typ in (0, 1)\n",
        "                                 for sent in DATA[lang][dts][typ]\n",
        "                                 for tok in sent)) for lang in SMPLS]\n",
        "\n",
        "datasizes['Vocab#']  = [len(set(tok for dts in ('trn', 'hld', 'dev', 'tst')\n",
        "                                for sent in DATA[lang][dts][0] for tok in sent))\n",
        "                        for lang in SMPLS]\n",
        "datasizes['Labels#'] = [len(set(tok for dts in ('trn', 'hld', 'dev', 'tst')\n",
        "                                for sent in DATA[lang][dts][1] for tok in sent))\n",
        "                        for lang in SMPLS]\n",
        "\n",
        "datasizes['Trn. Vocab#'] = [len(set(tok for sent in DATA[lang]['trn'][0]\n",
        "                                    for tok in sent)) for lang in SMPLS]\n",
        "datasizes['Trn. Label#'] = [len(set(tok for sent in DATA[lang]['trn'][1]\n",
        "                                    for tok in sent)) for lang in SMPLS]\n",
        "\n",
        "datasizes['Ood. Vocab%'] = [len(set(tok for dts in ('hld', 'dev', 'tst')\n",
        "                                    for sent in DATA[lang][dts][0]\n",
        "                                    for tok in sent).difference(\n",
        "                                        set(tok for sent in DATA[lang]['trn'][0]\n",
        "                                            for tok in sent)\n",
        "                                        )) for lang in SMPLS]\n",
        "datasizes['Ood. Label%'] = [len(set(tok for dts in ('hld', 'dev', 'tst')\n",
        "                                    for sent in DATA[lang][dts][1]\n",
        "                                    for tok in sent).difference(\n",
        "                                        set(tok for sent in DATA[lang]['trn'][0]\n",
        "                                            for tok in sent)\n",
        "                                        )) for lang in SMPLS]\n",
        "datasizes['Ood. Vocab%'] = 100 * datasizes['Ood. Vocab%'] / datasizes['Vocab#']\n",
        "datasizes['Ood. Label%'] = 100 * datasizes['Ood. Label%'] / datasizes['Labels#']\n",
        "\n",
        "datasizes "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Language</th>\n",
              "      <th>Training</th>\n",
              "      <th>Held-out</th>\n",
              "      <th>Devel</th>\n",
              "      <th>Test</th>\n",
              "      <th>AllToks#</th>\n",
              "      <th>Vocab#</th>\n",
              "      <th>Labels#</th>\n",
              "      <th>Trn. Vocab#</th>\n",
              "      <th>Trn. Label#</th>\n",
              "      <th>Ood. Vocab%</th>\n",
              "      <th>Ood. Label%</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Danish</td>\n",
              "      <td>175</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3421</td>\n",
              "      <td>3333</td>\n",
              "      <td>3280</td>\n",
              "      <td>2935</td>\n",
              "      <td>2886</td>\n",
              "      <td>11.941194</td>\n",
              "      <td>12.195122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>English</td>\n",
              "      <td>2006</td>\n",
              "      <td>354</td>\n",
              "      <td>590</td>\n",
              "      <td>0</td>\n",
              "      <td>13437</td>\n",
              "      <td>13127</td>\n",
              "      <td>12521</td>\n",
              "      <td>9589</td>\n",
              "      <td>9130</td>\n",
              "      <td>26.952083</td>\n",
              "      <td>27.561696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spanish</td>\n",
              "      <td>482</td>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3285</td>\n",
              "      <td>3064</td>\n",
              "      <td>2833</td>\n",
              "      <td>2695</td>\n",
              "      <td>2504</td>\n",
              "      <td>12.043081</td>\n",
              "      <td>12.072008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Croatian</td>\n",
              "      <td>4049</td>\n",
              "      <td>715</td>\n",
              "      <td>1588</td>\n",
              "      <td>0</td>\n",
              "      <td>23265</td>\n",
              "      <td>21769</td>\n",
              "      <td>20371</td>\n",
              "      <td>15146</td>\n",
              "      <td>14365</td>\n",
              "      <td>30.423997</td>\n",
              "      <td>30.091797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Indonesian-English</td>\n",
              "      <td>420</td>\n",
              "      <td>75</td>\n",
              "      <td>165</td>\n",
              "      <td>0</td>\n",
              "      <td>6185</td>\n",
              "      <td>5754</td>\n",
              "      <td>5284</td>\n",
              "      <td>4256</td>\n",
              "      <td>3887</td>\n",
              "      <td>26.034063</td>\n",
              "      <td>27.346707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Italian</td>\n",
              "      <td>504</td>\n",
              "      <td>89</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4941</td>\n",
              "      <td>4619</td>\n",
              "      <td>4383</td>\n",
              "      <td>4046</td>\n",
              "      <td>3836</td>\n",
              "      <td>12.405283</td>\n",
              "      <td>12.616929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Dutch</td>\n",
              "      <td>797</td>\n",
              "      <td>141</td>\n",
              "      <td>314</td>\n",
              "      <td>0</td>\n",
              "      <td>7875</td>\n",
              "      <td>6642</td>\n",
              "      <td>5385</td>\n",
              "      <td>3581</td>\n",
              "      <td>2892</td>\n",
              "      <td>46.085516</td>\n",
              "      <td>49.637883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Slovenian</td>\n",
              "      <td>3969</td>\n",
              "      <td>701</td>\n",
              "      <td>1557</td>\n",
              "      <td>0</td>\n",
              "      <td>17673</td>\n",
              "      <td>15963</td>\n",
              "      <td>14501</td>\n",
              "      <td>11229</td>\n",
              "      <td>10276</td>\n",
              "      <td>29.656080</td>\n",
              "      <td>30.315151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Serbian</td>\n",
              "      <td>3517</td>\n",
              "      <td>621</td>\n",
              "      <td>1381</td>\n",
              "      <td>0</td>\n",
              "      <td>20521</td>\n",
              "      <td>18777</td>\n",
              "      <td>17551</td>\n",
              "      <td>13705</td>\n",
              "      <td>12912</td>\n",
              "      <td>27.011770</td>\n",
              "      <td>27.491311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Turkish</td>\n",
              "      <td>486</td>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5837</td>\n",
              "      <td>4326</td>\n",
              "      <td>3992</td>\n",
              "      <td>3760</td>\n",
              "      <td>3501</td>\n",
              "      <td>13.083680</td>\n",
              "      <td>13.677355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Turkish-German</td>\n",
              "      <td>680</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7856</td>\n",
              "      <td>6156</td>\n",
              "      <td>5752</td>\n",
              "      <td>5514</td>\n",
              "      <td>5194</td>\n",
              "      <td>10.428850</td>\n",
              "      <td>10.639777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Language  Training  ...  Ood. Vocab%  Ood. Label%\n",
              "0               Danish       175  ...    11.941194    12.195122\n",
              "1              English      2006  ...    26.952083    27.561696\n",
              "2              Spanish       482  ...    12.043081    12.072008\n",
              "3             Croatian      4049  ...    30.423997    30.091797\n",
              "4   Indonesian-English       420  ...    26.034063    27.346707\n",
              "5              Italian       504  ...    12.405283    12.616929\n",
              "6                Dutch       797  ...    46.085516    49.637883\n",
              "7            Slovenian      3969  ...    29.656080    30.315151\n",
              "8              Serbian      3517  ...    27.011770    27.491311\n",
              "9              Turkish       486  ...    13.083680    13.677355\n",
              "10      Turkish-German       680  ...    10.428850    10.639777\n",
              "\n",
              "[11 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZUyx0JVEMnj"
      },
      "source": [
        "### Sequence classification using PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdjItmlUpj3k"
      },
      "source": [
        "##### Preprocessing\n",
        "In this step, we convert the sequence of tokens into an embedding matrix. \n",
        "This step relies on tokenizers and pre-trained models from ``huggingface``.\n",
        "This seperation of preprocessing should allow for training other classifiers \n",
        "than neural versions using ``sklearn`` or other packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qkRzWpGY-fW"
      },
      "source": [
        "for lang in SMPLS:\n",
        "  # load tokenizer model from ``huggingface``\n",
        "  for dts in DATA[lang]:\n",
        "    for inp, out in zip(DATA[lang][dts][0], DATA[lang][dts][1]):\n",
        "      tinp = []\n",
        "      tout = []\n",
        "      for intok, outok in zip(inp, out):\n",
        "        pass"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0rYO-eeEMy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08b5422-8fc2-4ac4-dd8e-99cbcee60afc"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5arwc2T385K"
      },
      "source": [
        "### Sequence classification using HMM models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtNuRD1539GR"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}